{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download historical stock data from Yahoo Finance\n",
    "def download_stock_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return data\n",
    "\n",
    "# Function to preprocess stock data\n",
    "def preprocess_data(data):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "    return scaled_data, scaler\n",
    "\n",
    "# Function to create sequences for LSTM model\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    target = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[i:i + sequence_length]\n",
    "        label = data[i + sequence_length][3]  # Closing price as the target\n",
    "        sequences.append(seq)\n",
    "        target.append(label)\n",
    "    return np.array(sequences), np.array(target)\n",
    "\n",
    "# Function to build and train LSTM model\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Function to train the LSTM model\n",
    "def train_model(X_train, y_train, epochs=50, batch_size=32):\n",
    "    model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    return model\n",
    "\n",
    "# Function to evaluate the model on test data\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask application for prediction\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Endpoint for predicting stock prices\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    input_data = np.array(data['input_data'])\n",
    "    input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1])\n",
    "    prediction = model.predict(input_data)\n",
    "    return jsonify({'prediction': prediction.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 7s 14ms/step - loss: 0.1138\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0316\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0208\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0148\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0136\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0132\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0124\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0123\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0122\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0119\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0118\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0116\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0114\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0112\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0110\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0108\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0107\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0107\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0101\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0101\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0100\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0095\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0093\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0090\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0088\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0086\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0083\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0081\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0080\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0080\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0077\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0077\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0075\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0075\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0078\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0074\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0070\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0070\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0069\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0069\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0069\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0067\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0067\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0073\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0069\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0081\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0072\n",
      "2/2 [==============================] - 1s 7ms/step\n",
      "Mean Squared Error on Test Data: 0.009501869536725724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Desktop\\Assignment2\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Download historical stock data\n",
    "    ticker = \"AAPL\"\n",
    "    start_date = \"2022-01-01\"\n",
    "    end_date = \"2023-01-01\"\n",
    "    stock_data = download_stock_data(ticker, start_date, end_date)\n",
    "\n",
    "    # Preprocess data\n",
    "    scaled_data, scaler = preprocess_data(stock_data)\n",
    "\n",
    "    # Create sequences for LSTM model\n",
    "    sequence_length = 10\n",
    "    X, y = create_sequences(scaled_data, sequence_length)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the LSTM model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = evaluate_model(model, X_test, y_test)\n",
    "    print(f\"Mean Squared Error on Test Data: {mse}\")\n",
    "\n",
    "    # Save the model and scaler\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    model.save('stock_prediction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Desktop\\Assignment2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Run Flask application\n",
    "app.run(debug=True, port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "284622435fb6bedbdbea95918836920056632c21381432dd4986acf2b6bfea8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
